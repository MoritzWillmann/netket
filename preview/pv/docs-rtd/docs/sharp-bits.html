<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>🔪 The Sharp Bits 🔪 &mdash; netket v3.0 documentation</title><link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../_static/graphviz.css" type="text/css" />
      <link rel="stylesheet" href="../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" type="text/css" />
      <link rel="stylesheet" href="../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  <script id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/doctools.js"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Defining Custom Models" href="custom_models.html" />
    <link rel="prev" title="The Drivers API" href="drivers.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="../index.html" class="icon icon-home"> netket<img src="../_static/logonav.png" class="logo" alt="Logo"/>
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption"><span class="caption-text">Tutorials</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../tutorials/netket3.html">Ground-State Variational Search with NetKet</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tutorials/jax.html">Using JAX as a backend in NetKet - Feature Preview for v3.0</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tutorials/G-CNN_Honeycomb.html">Using a group convolutional neural network to learn the ground-state of a symmetric spin model</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tutorials/j1j2.html">Variational Monte Carlo with Neural Networks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tutorials/Heisenberg1d.html">Learning the ground-state of a spin model with different Neural Networks available in NetKet</a></li>
</ul>
<p class="caption"><span class="caption-text">Reference Documentation</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="getting_started.html">Getting Started</a></li>
<li class="toctree-l1"><a class="reference internal" href="changelog.html">Change Log</a></li>
<li class="toctree-l1"><a class="reference internal" href="superop.html">The Lindblad Master Equation</a></li>
<li class="toctree-l1"><a class="reference internal" href="hilbert.html">The Hilbert module</a></li>
<li class="toctree-l1"><a class="reference internal" href="operator.html">The Operator module</a></li>
<li class="toctree-l1"><a class="reference internal" href="varstate.html">The Variational State Interface</a></li>
<li class="toctree-l1"><a class="reference internal" href="sr.html">Quantum Geometric Tensor and Stochastic Reconfiguration</a></li>
<li class="toctree-l1"><a class="reference internal" href="drivers.html">The Drivers API</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">🔪 The Sharp Bits 🔪</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#parallelization">Parallelization</a></li>
<li class="toctree-l2"><a class="reference internal" href="#running-on-cpu-when-gpus-are-present">Running on CPU when GPUs are present</a></li>
<li class="toctree-l2"><a class="reference internal" href="#using-gpus">Using GPUs</a></li>
<li class="toctree-l2"><a class="reference internal" href="#nans-in-training-and-loss-of-precision">NaNs in training and loss of precision</a></li>
</ul>
</li>
</ul>
<p class="caption"><span class="caption-text">Extending NetKet</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="custom_models.html">Defining Custom Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="custom_expect.html">Overriding defaults in NetKet</a></li>
<li class="toctree-l1"><a class="reference internal" href="custom_preconditioners.html">Defining Custom Preconditioners</a></li>
<li class="toctree-l1"><a class="reference internal" href="custom_operator.html">Defining Custom Operators</a></li>
</ul>
<p class="caption"><span class="caption-text">Developer Documentation</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="contributing.html">Contributing to NetKet</a></li>
<li class="toctree-l1"><a class="reference internal" href="writing-tests.html">Writing Tests</a></li>
</ul>
<p class="caption"><span class="caption-text">API documentation</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="api-stability.html">API Stability</a></li>
<li class="toctree-l1"><a class="reference internal" href="api.html">Public API</a></li>
<li class="toctree-l1"><a class="reference internal" href="api-experimental.html">Experimental API</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">netket</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home"></a> &raquo;</li>
      <li>🔪 The Sharp Bits 🔪</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../_sources/docs/sharp-bits.md.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  
<style>
/* CSS overrides for sphinx_rtd_theme */

/* 24px margin */
.nbinput.nblast.container,
.nboutput.nblast.container {
    margin-bottom: 19px;  /* padding has already 5px */
}

/* ... except between code cells! */
.nblast.container + .nbinput.container {
    margin-top: -19px;
}

.admonition > p:before {
    margin-right: 4px;  /* make room for the exclamation icon */
}

/* Fix math alignment, see https://github.com/rtfd/sphinx_rtd_theme/pull/686 */
.math {
    text-align: unset;
}
</style>
<div class="section" id="the-sharp-bits">
<h1>🔪 The Sharp Bits 🔪<a class="headerlink" href="#the-sharp-bits" title="Permalink to this headline"></a></h1>
<p>Read ahead for some pitfalls, counter-intuitive behavior, and sharp edges that we had to introduce in order to make this work.</p>
<div class="section" id="parallelization">
<span id="id1"></span><h2>Parallelization<a class="headerlink" href="#parallelization" title="Permalink to this headline"></a></h2>
<p>Netket computations run mostly via Jax’s XLA.
Compared to NetKet 2, this means that we can automatically benefit from multiple CPUs without having to use MPI.
This is because mathematical operations such as matrix multiplications and overs will be split into sub-chunks and distributed across different cpus.
This behaviour is trigered only for matrices/vectors above a certain size, and will not perform particularly good for small matrices or if you have many cpu cores.
To disable this behaviour, refer to <a class="reference external" href="https://github.com/google/jax/issues/743">Jax#743</a>, which mainly suggest defining the two env variables:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nb">export</span> <span class="nv">XLA_FLAGS</span><span class="o">=</span><span class="s2">&quot;--xla_cpu_multi_thread_eigen=false intra_op_parallelism_threads=1&quot;</span>
</pre></div>
</div>
<p>Usually we have noticed that the best performance is achieved by combining both BLAS parallelism and MPI, for example by guaranteeing between 2-4 (depending on your problem size) cpus to every MPI thread.</p>
<p>Note that when using <code class="code docutils literal notranslate"><span class="pre">netket</span></code> it is crucial to run Python with the same implementation and version of MPI that the <code class="code docutils literal notranslate"><span class="pre">mpi4py</span></code> module is compiled against.
If you encounter issues, you can check whether your MPI environment is set up properly by running:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ mpirun -np 2 python3 -m netket.tools.check_mpi
mpi4py_available             : True
mpi4jax_available            : True
avalable_cpus (rank 0)       : 12
n_nodes                      : 1
mpi4py | MPI version         : (3, 1)
mpi4py | MPI library_version : Open MPI v4.1.0, package: Open MPI brew@BigSur Distribution, ident: 4.1.0,  repo rev: v4.1.0, Dec 18, 2020
</pre></div>
</div>
<p>This should print some basic information about the MPI installation and, in particular, pick up the correct <code class="docutils literal notranslate"><span class="pre">n_nodes</span></code>.
If you get the same output multiple times, each with <code class="code docutils literal notranslate"><span class="pre">n_nodes</span> <span class="pre">:</span> <span class="pre">1</span></code>, this is a clear sign that your MPI setup is broken.
The tool above also reports the number of (logical) CPUs that might be subscribed by Jax on every independent MPI rank during linear algebra operations.
Be mindfull that Jax, in general, is like an invasive plant and tends to use all resources that he can access, and
the environment variables above might not prevent it from making use of the <code class="docutils literal notranslate"><span class="pre">available_cpus</span></code>.
On Mac it is not possible to control this number.
On Linux it can be controlled using <code class="docutils literal notranslate"><span class="pre">taskset</span></code> or <code class="docutils literal notranslate"><span class="pre">--bind-to</span> <span class="pre">core</span></code> when using <code class="docutils literal notranslate"><span class="pre">mpirun</span></code>.</p>
</div>
<div class="section" id="running-on-cpu-when-gpus-are-present">
<span id="running-on-cpu"></span><h2>Running on CPU when GPUs are present<a class="headerlink" href="#running-on-cpu-when-gpus-are-present" title="Permalink to this headline"></a></h2>
<p>If you have the CUDA version of jaxlib installed, then computations will, by default, run on the GPU.
For small systems this will be very inefficient. To check if this is the case, run the following code:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">jax</span>
<span class="nb">print</span><span class="p">(</span><span class="n">jax</span><span class="o">.</span><span class="n">devices</span><span class="p">())</span>
</pre></div>
</div>
<p>If the output is <code class="code docutils literal notranslate"><span class="pre">[CpuDevice(id=0)]</span></code>, then computations will run by default on the CPU, if instead you see
something like <code class="code docutils literal notranslate"><span class="pre">[GpuDevice(id=0)]</span></code> computations will run on the GPU.</p>
<p>To force Jax/XLA to run comutations on the CPU, set the environment variable</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nb">export</span> <span class="nv">JAX_PLATFORM_NAME</span><span class="o">=</span><span class="s2">&quot;cpu&quot;</span>
</pre></div>
</div>
</div>
<div class="section" id="using-gpus">
<span id="gpus"></span><h2>Using GPUs<a class="headerlink" href="#using-gpus" title="Permalink to this headline"></a></h2>
<p>Jax supports GPUs, so your calculations should run fine on GPU, however there are a few gotchas:</p>
<ul class="simple">
<li><p>GPUs have a much higher overhead, therefore you will see very bad performance at small system size (typically below 40 spins)</p></li>
<li><p>Not all Metropolis Transition Rules work on GPUs. To go around that, those rules have been rewritten in numpy in order to run on the cpu, therefore you might need to use <a class="reference internal" href="_generated/samplers/netket.sampler.MetropolisSamplerNumpy.html#netket-sampler-metropolissamplernumpy"><span class="std std-ref">netket.sampler.MetropolisSamplerNumpy</span></a> instead of <a class="reference internal" href="_generated/samplers/netket.sampler.MetropolisSampler.html#netket-sampler-metropolissampler"><span class="std std-ref">netket.sampler.MetropolisSampler</span></a>.</p></li>
</ul>
<p>Eventually we would like the selection to be automatic, but this has not yet been implemented.</p>
<p>Please open tickets if you find issues!</p>
</div>
<div class="section" id="nans-in-training-and-loss-of-precision">
<span id="nan"></span><h2>NaNs in training and loss of precision<a class="headerlink" href="#nans-in-training-and-loss-of-precision" title="Permalink to this headline"></a></h2>
<p>If you find NaNs while training, especially if you are using your own model, there might be a few reasons:</p>
<ul class="simple">
<li><p>It might simply be a precision issue, as you might be using single precision (<code class="code docutils literal notranslate"><span class="pre">np.float32</span></code>, <code class="code docutils literal notranslate"><span class="pre">np.complex64</span></code>) instead of double precision (<code class="code docutils literal notranslate"><span class="pre">np.float64</span></code>, <code class="code docutils literal notranslate"><span class="pre">np.complex128</span></code>). Be careful that if you use <code class="code docutils literal notranslate"><span class="pre">float</span></code> and <code class="code docutils literal notranslate"><span class="pre">complex</span></code> as dtype, they will not always behave as you expect!
They are known as <a class="reference external" href="https://jax.readthedocs.io/en/latest/type_promotion.html?highlight=type-promotion">weak dtypes</a>, and when multiplied by a single-precision number they will be converted to single precision.
This issue might manifest especially when using Flax, which respects type promotion, as opposed to <code class="docutils literal notranslate"><span class="pre">jax.example_libraries.stax</span></code>, which does not.</p></li>
<li><p>Check the initial parameters. In the NetKet 2 models were always initialized with weights normally distributed.
In Netket 3, <code class="docutils literal notranslate"><span class="pre">netket.nn</span></code> layers use the same default (normal distribution with standard deviation 0.01) but
if you use general flax layers they might use different initializers.
different initialisation distributions have particoularly strong effects when working with complex-valued models.
A good way to enforce the same distribution across all your weights, similar to NetKet 2 behaviour, is to use <a class="reference internal" href="_generated/variational/netket.vqs.VariationalState.html#netket.vqs.VariationalState.init_parameters" title="netket.vqs.VariationalState.init_parameters"><code class="xref py py-meth docutils literal notranslate"><span class="pre">init_parameters()</span></code></a>.</p></li>
</ul>
</div>
</div>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="drivers.html" class="btn btn-neutral float-left" title="The Drivers API" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="custom_models.html" class="btn btn-neutral float-right" title="Defining Custom Models" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2019-2021, The Netket authors - All rights reserved.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>
 

<script type="text/javascript">
    jQuery(function () {
        SphinxRtdTheme.Navigation.enable(true);
      })
</script>

<!-- Temporary footer
<div class="footer-wip">
  <div class="footer-wip-content">
    This documentation refers to an unreleased version of Netket.
  </div>
</div>
-->

<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-118013987-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());
  gtag('config', 'UA-118013987-1');
</script>

<script type="application/ld+json">
{
  "@context": "http://schema.org",
  "@type": "Organization",
  "url": "https://www.netket.org",
  "name": "NetKet",
  "founder": "Giuseppe Carleo",
  "foundingDate": "2018-04-24",
  "foundingLocation" : "New York",
  "logo": "https://www.netket.org/img/logo_small.jpg",
  "sameAs": [
    "https://twitter.com/NetKetOrg",
    "https://github.com/NetKet/netket"
  ],
  "description" : "Netket is an open-source project delivering cutting-edge
  methods for the study of many-body quantum systems with artificial neural
  networks and machine learning techniques."
}
</script>


</body>
</html>