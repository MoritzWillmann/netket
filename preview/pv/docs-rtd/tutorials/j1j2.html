<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Variational Monte Carlo with Neural Networks &mdash; netket v3.0 documentation</title><link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../_static/graphviz.css" type="text/css" />
      <link rel="stylesheet" href="../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" type="text/css" />
      <link rel="stylesheet" href="../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  <script id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/doctools.js"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
        <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
        <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true, "ignoreClass": "tex2jax_ignore|mathjax_ignore|document", "processClass": "tex2jax_process|mathjax_process|math|output_area"}})</script>
    <script src="../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Learning the ground-state of a spin model with different Neural Networks available in NetKet" href="Heisenberg1d.html" />
    <link rel="prev" title="Using a group convolutional neural network to learn the ground-state of a symmetric spin model" href="G-CNN_Honeycomb.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="../index.html" class="icon icon-home"> netket<img src="../_static/logonav.png" class="logo" alt="Logo"/>
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption"><span class="caption-text">Tutorials</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="netket3.html">Ground-State Variational Search with NetKet</a></li>
<li class="toctree-l1"><a class="reference internal" href="jax.html">Using JAX as a backend in NetKet - Feature Preview for v3.0</a></li>
<li class="toctree-l1"><a class="reference internal" href="G-CNN_Honeycomb.html">Using a group convolutional neural network to learn the ground-state of a symmetric spin model</a></li>
<li class="toctree-l1"><a class="reference internal" href="G-CNN_Honeycomb.html#G-CNNs-are-generalizations-of-CNNs-to-non-abelian-groups">G-CNNs are generalizations of CNNs to non-abelian groups</a></li>
<li class="toctree-l1"><a class="reference internal" href="G-CNN_Honeycomb.html#Defining-the-Hamiltonian">Defining the Hamiltonian</a></li>
<li class="toctree-l1"><a class="reference internal" href="G-CNN_Honeycomb.html#Defining-the-GCNN">Defining the GCNN</a></li>
<li class="toctree-l1"><a class="reference internal" href="G-CNN_Honeycomb.html#Variational-Monte-Carlo">Variational Monte Carlo</a></li>
<li class="toctree-l1"><a class="reference internal" href="G-CNN_Honeycomb.html#Checking-with-ED">Checking with ED</a></li>
<li class="toctree-l1"><a class="reference internal" href="G-CNN_Honeycomb.html#Simulating-A-Larger-Lattice">Simulating A Larger Lattice</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Variational Monte Carlo with Neural Networks</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#Objectives:">Objectives:</a></li>
<li class="toctree-l2"><a class="reference internal" href="#1)-Defining-a-Custom-Hamiltonian">1) Defining a Custom Hamiltonian</a></li>
<li class="toctree-l2"><a class="reference internal" href="#2)-Defining-the-Machine">2) Defining the Machine</a></li>
<li class="toctree-l2"><a class="reference internal" href="#3)-Variational-Monte-Carlo-Optimisation">3) Variational Monte Carlo Optimisation</a></li>
<li class="toctree-l2"><a class="reference internal" href="#4)-Measuring-Observables">4) Measuring Observables</a></li>
<li class="toctree-l2"><a class="reference internal" href="#5)-Data-Visualisation">5) Data Visualisation</a></li>
<li class="toctree-l2"><a class="reference internal" href="#6)-Sanity-Check:-Exact-Diagonalisation">6) Sanity Check: Exact Diagonalisation</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="Heisenberg1d.html">Learning the ground-state of a spin model with different Neural Networks available in NetKet</a></li>
</ul>
<p class="caption"><span class="caption-text">Reference Documentation</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../docs/getting_started.html">Getting Started</a></li>
<li class="toctree-l1"><a class="reference internal" href="../docs/changelog.html">Change Log</a></li>
<li class="toctree-l1"><a class="reference internal" href="../docs/superop.html">The Lindblad Master Equation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../docs/hilbert.html">The Hilbert module</a></li>
<li class="toctree-l1"><a class="reference internal" href="../docs/operator.html">The Operator module</a></li>
<li class="toctree-l1"><a class="reference internal" href="../docs/varstate.html">The Variational State Interface</a></li>
<li class="toctree-l1"><a class="reference internal" href="../docs/sr.html">Quantum Geometric Tensor and Stochastic Reconfiguration</a></li>
<li class="toctree-l1"><a class="reference internal" href="../docs/drivers.html">The Drivers API</a></li>
<li class="toctree-l1"><a class="reference internal" href="../docs/sharp-bits.html">🔪 The Sharp Bits 🔪</a></li>
</ul>
<p class="caption"><span class="caption-text">Extending NetKet</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../docs/custom_models.html">Defining Custom Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="../docs/custom_expect.html">Overriding defaults in NetKet</a></li>
<li class="toctree-l1"><a class="reference internal" href="../docs/custom_preconditioners.html">Defining Custom Preconditioners</a></li>
<li class="toctree-l1"><a class="reference internal" href="../docs/custom_operator.html">Defining Custom Operators</a></li>
</ul>
<p class="caption"><span class="caption-text">Developer Documentation</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../docs/contributing.html">Contributing to NetKet</a></li>
<li class="toctree-l1"><a class="reference internal" href="../docs/writing-tests.html">Writing Tests</a></li>
</ul>
<p class="caption"><span class="caption-text">API documentation</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../docs/api-stability.html">API Stability</a></li>
<li class="toctree-l1"><a class="reference internal" href="../docs/api.html">Public API</a></li>
<li class="toctree-l1"><a class="reference internal" href="../docs/api-experimental.html">Experimental API</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">netket</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home"></a> &raquo;</li>
      <li>Variational Monte Carlo with Neural Networks</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../_sources/tutorials/j1j2.ipynb.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  
<style>
/* CSS for nbsphinx extension */

/* remove conflicting styling from Sphinx themes */
div.nbinput.container div.prompt *,
div.nboutput.container div.prompt *,
div.nbinput.container div.input_area pre,
div.nboutput.container div.output_area pre,
div.nbinput.container div.input_area .highlight,
div.nboutput.container div.output_area .highlight {
    border: none;
    padding: 0;
    margin: 0;
    box-shadow: none;
}

div.nbinput.container > div[class*=highlight],
div.nboutput.container > div[class*=highlight] {
    margin: 0;
}

div.nbinput.container div.prompt *,
div.nboutput.container div.prompt * {
    background: none;
}

div.nboutput.container div.output_area .highlight,
div.nboutput.container div.output_area pre {
    background: unset;
}

div.nboutput.container div.output_area div.highlight {
    color: unset;  /* override Pygments text color */
}

/* avoid gaps between output lines */
div.nboutput.container div[class*=highlight] pre {
    line-height: normal;
}

/* input/output containers */
div.nbinput.container,
div.nboutput.container {
    display: -webkit-flex;
    display: flex;
    align-items: flex-start;
    margin: 0;
    width: 100%;
}
@media (max-width: 540px) {
    div.nbinput.container,
    div.nboutput.container {
        flex-direction: column;
    }
}

/* input container */
div.nbinput.container {
    padding-top: 5px;
}

/* last container */
div.nblast.container {
    padding-bottom: 5px;
}

/* input prompt */
div.nbinput.container div.prompt pre {
    color: #307FC1;
}

/* output prompt */
div.nboutput.container div.prompt pre {
    color: #BF5B3D;
}

/* all prompts */
div.nbinput.container div.prompt,
div.nboutput.container div.prompt {
    width: 4.5ex;
    padding-top: 5px;
    position: relative;
    user-select: none;
}

div.nbinput.container div.prompt > div,
div.nboutput.container div.prompt > div {
    position: absolute;
    right: 0;
    margin-right: 0.3ex;
}

@media (max-width: 540px) {
    div.nbinput.container div.prompt,
    div.nboutput.container div.prompt {
        width: unset;
        text-align: left;
        padding: 0.4em;
    }
    div.nboutput.container div.prompt.empty {
        padding: 0;
    }

    div.nbinput.container div.prompt > div,
    div.nboutput.container div.prompt > div {
        position: unset;
    }
}

/* disable scrollbars on prompts */
div.nbinput.container div.prompt pre,
div.nboutput.container div.prompt pre {
    overflow: hidden;
}

/* input/output area */
div.nbinput.container div.input_area,
div.nboutput.container div.output_area {
    -webkit-flex: 1;
    flex: 1;
    overflow: auto;
}
@media (max-width: 540px) {
    div.nbinput.container div.input_area,
    div.nboutput.container div.output_area {
        width: 100%;
    }
}

/* input area */
div.nbinput.container div.input_area {
    border: 1px solid #e0e0e0;
    border-radius: 2px;
    /*background: #f5f5f5;*/
}

/* override MathJax center alignment in output cells */
div.nboutput.container div[class*=MathJax] {
    text-align: left !important;
}

/* override sphinx.ext.imgmath center alignment in output cells */
div.nboutput.container div.math p {
    text-align: left;
}

/* standard error */
div.nboutput.container div.output_area.stderr {
    background: #fdd;
}

/* ANSI colors */
.ansi-black-fg { color: #3E424D; }
.ansi-black-bg { background-color: #3E424D; }
.ansi-black-intense-fg { color: #282C36; }
.ansi-black-intense-bg { background-color: #282C36; }
.ansi-red-fg { color: #E75C58; }
.ansi-red-bg { background-color: #E75C58; }
.ansi-red-intense-fg { color: #B22B31; }
.ansi-red-intense-bg { background-color: #B22B31; }
.ansi-green-fg { color: #00A250; }
.ansi-green-bg { background-color: #00A250; }
.ansi-green-intense-fg { color: #007427; }
.ansi-green-intense-bg { background-color: #007427; }
.ansi-yellow-fg { color: #DDB62B; }
.ansi-yellow-bg { background-color: #DDB62B; }
.ansi-yellow-intense-fg { color: #B27D12; }
.ansi-yellow-intense-bg { background-color: #B27D12; }
.ansi-blue-fg { color: #208FFB; }
.ansi-blue-bg { background-color: #208FFB; }
.ansi-blue-intense-fg { color: #0065CA; }
.ansi-blue-intense-bg { background-color: #0065CA; }
.ansi-magenta-fg { color: #D160C4; }
.ansi-magenta-bg { background-color: #D160C4; }
.ansi-magenta-intense-fg { color: #A03196; }
.ansi-magenta-intense-bg { background-color: #A03196; }
.ansi-cyan-fg { color: #60C6C8; }
.ansi-cyan-bg { background-color: #60C6C8; }
.ansi-cyan-intense-fg { color: #258F8F; }
.ansi-cyan-intense-bg { background-color: #258F8F; }
.ansi-white-fg { color: #C5C1B4; }
.ansi-white-bg { background-color: #C5C1B4; }
.ansi-white-intense-fg { color: #A1A6B2; }
.ansi-white-intense-bg { background-color: #A1A6B2; }

.ansi-default-inverse-fg { color: #FFFFFF; }
.ansi-default-inverse-bg { background-color: #000000; }

.ansi-bold { font-weight: bold; }
.ansi-underline { text-decoration: underline; }


div.nbinput.container div.input_area div[class*=highlight] > pre,
div.nboutput.container div.output_area div[class*=highlight] > pre,
div.nboutput.container div.output_area div[class*=highlight].math,
div.nboutput.container div.output_area.rendered_html,
div.nboutput.container div.output_area > div.output_javascript,
div.nboutput.container div.output_area:not(.rendered_html) > img{
    padding: 5px;
    margin: 0;
}

/* fix copybtn overflow problem in chromium (needed for 'sphinx_copybutton') */
div.nbinput.container div.input_area > div[class^='highlight'],
div.nboutput.container div.output_area > div[class^='highlight']{
    overflow-y: hidden;
}

/* hide copybtn icon on prompts (needed for 'sphinx_copybutton') */
.prompt a.copybtn {
    display: none;
}

/* Some additional styling taken form the Jupyter notebook CSS */
div.rendered_html table {
  border: none;
  border-collapse: collapse;
  border-spacing: 0;
  color: black;
  font-size: 12px;
  table-layout: fixed;
}
div.rendered_html thead {
  border-bottom: 1px solid black;
  vertical-align: bottom;
}
div.rendered_html tr,
div.rendered_html th,
div.rendered_html td {
  text-align: right;
  vertical-align: middle;
  padding: 0.5em 0.5em;
  line-height: normal;
  white-space: normal;
  max-width: none;
  border: none;
}
div.rendered_html th {
  font-weight: bold;
}
div.rendered_html tbody tr:nth-child(odd) {
  background: #f5f5f5;
}
div.rendered_html tbody tr:hover {
  background: rgba(66, 165, 245, 0.2);
}

/* CSS overrides for sphinx_rtd_theme */

/* 24px margin */
.nbinput.nblast.container,
.nboutput.nblast.container {
    margin-bottom: 19px;  /* padding has already 5px */
}

/* ... except between code cells! */
.nblast.container + .nbinput.container {
    margin-top: -19px;
}

.admonition > p:before {
    margin-right: 4px;  /* make room for the exclamation icon */
}

/* Fix math alignment, see https://github.com/rtfd/sphinx_rtd_theme/pull/686 */
.math {
    text-align: unset;
}
</style>
<div class="section" id="Variational-Monte-Carlo-with-Neural-Networks">
<h1>Variational Monte Carlo with Neural Networks<a class="headerlink" href="#Variational-Monte-Carlo-with-Neural-Networks" title="Permalink to this headline"></a></h1>
<p>In this tutorial we will use NetKet to obtain the ground state of the J1-J2 model in one-dimension with periodic boundary conditions, using a Neural Network variational wave-function. The Hamiltonian of the model is given by:</p>
<div class="math notranslate nohighlight">
\[H = \sum_{i=1}^{L} J_{1}\vec{\sigma}_{i} \cdot \vec{\sigma}_{i+1} + J_{2} \vec{\sigma}_{i} \cdot \vec{\sigma}_{i+2}\]</div>
<p>where the sum is over sites of the 1-D chain. Here <span class="math notranslate nohighlight">\(\vec{\sigma}=(\sigma^x,\sigma^y,\sigma^z)\)</span> is the vector of Pauli matrices.</p>
<p>We will also explore some useful functionalities provided by the package.</p>
<div class="section" id="Objectives:">
<h2>Objectives:<a class="headerlink" href="#Objectives:" title="Permalink to this headline"></a></h2>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>1. Defining custom Hamiltonians
2. Defining the machine (variational ansatz)
3. Variational Monte Carlo Optimisation
4. Measuring observables
5. Data Visualisation
6. Sanity Check: Exact Diagonalisation
</pre></div>
</div>
<p>Let’s start.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[1]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span># ensure we run on the CPU
import os
os.environ[&quot;JAX_PLATFORM_NAME&quot;] = &quot;cpu&quot;

# Import netket library
import netket as nk

# Helper libraries
import numpy as np
import matplotlib.pyplot as plt
</pre></div>
</div>
</div>
</div>
<div class="section" id="1)-Defining-a-Custom-Hamiltonian">
<h2>1) Defining a Custom Hamiltonian<a class="headerlink" href="#1)-Defining-a-Custom-Hamiltonian" title="Permalink to this headline"></a></h2>
<p>The first thing to do is to define the graph (lattice) on which to specify the Hamiltonian. Here we would like to build a one-dimensional graph with both nearest and next nearest neighbour bonds. The graph is created in the <code class="docutils literal notranslate"><span class="pre">nk.graph.CustomGraph</span></code> class. To initialise the class we simply provide a list of edges in the <code class="docutils literal notranslate"><span class="pre">[[site_i,</span> <span class="pre">site_j,</span> <span class="pre">edge_color],</span> <span class="pre">...]</span></code></p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[2]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span>#Couplings J1 and J2
J = [1, 0.2]
L = 14
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[3]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span># Define custom graph
edge_colors = []
for i in range(L):
    edge_colors.append([i, (i+1)%L, 1])
    edge_colors.append([i, (i+2)%L, 2])

# Define the netket graph object
g = nk.graph.Graph(edges=edge_colors)
</pre></div>
</div>
</div>
<p>We specify a different <code class="docutils literal notranslate"><span class="pre">color</span></code> for each type of bond so as to define a different operator for each of them. Next, we define the relevant bond operators.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[4]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span>#Sigma^z*Sigma^z interactions
sigmaz = [[1, 0], [0, -1]]
mszsz = (np.kron(sigmaz, sigmaz))

#Exchange interactions
exchange = np.asarray([[0, 0, 0, 0], [0, 0, 2, 0], [0, 2, 0, 0], [0, 0, 0, 0]])

bond_operator = [
    (J[0] * mszsz).tolist(),
    (J[1] * mszsz).tolist(),
    (-J[0] * exchange).tolist(),
    (J[1] * exchange).tolist(),
]

bond_color = [1, 2, 1, 2]
</pre></div>
</div>
</div>
<p><strong>Side Remark</strong>: Notice the minus sign in front of the exchange. This is simply a basis rotation corresponding to the Marshall sign rule (as an exercise, change the sign of this exchange and observe that the exact diagonalization results in Section 6 do not change). The goal of this basis rotation is to speed up the convergence of the Monte Carlo simulations of the wave-function (by providing a good variational sign structure to start with), but in principle the converged results should be
identical in both bases. Note further that this sign change is useful at low frustration (such as here <span class="math notranslate nohighlight">\(J_2=0.2\)</span>), but may actually be not optimal at stronger frustration. As a bonus exercise, repeat the calculation with <span class="math notranslate nohighlight">\(J_2=0.8\)</span>, and see which basis (<em>i.e.</em> which sign in front of the exchange) leads to faster convergence.</p>
<p>Before defining the Hamiltonian, we also need to specify the Hilbert space. For our case, this would be the chain spin-half degrees of freedom.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[5]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span># Spin based Hilbert Space
hi = nk.hilbert.Spin(s=0.5, total_sz=0.0, N=g.n_nodes)
</pre></div>
</div>
</div>
<p>Note that we impose here the total magnetization to be zero (it turns out to be the correct magnetization for the ground-state). As an exercise, check that the energy of the lowest state in other magnetization sectors is larger.</p>
<p>Next, we define the custom graph Hamiltonian using the <code class="docutils literal notranslate"><span class="pre">nk.operator.GraphOperator</span></code> class, by providing the hilbert space <code class="docutils literal notranslate"><span class="pre">hi</span></code>, the bond operators <code class="docutils literal notranslate"><span class="pre">bondops=bond_operator</span></code> and the corresponding bond color <code class="docutils literal notranslate"><span class="pre">bondops_colors=bond_color</span></code>. The information about the graph (bonds and bond colors) are contained within the <code class="docutils literal notranslate"><span class="pre">nk.hilbert.Spin</span></code> object <code class="docutils literal notranslate"><span class="pre">hi</span></code>.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[6]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span># Custom Hamiltonian operator
op = nk.operator.GraphOperator(hi, graph=g, bond_ops=bond_operator, bond_ops_colors=bond_color)
</pre></div>
</div>
</div>
</div>
<div class="section" id="2)-Defining-the-Machine">
<h2>2) Defining the Machine<a class="headerlink" href="#2)-Defining-the-Machine" title="Permalink to this headline"></a></h2>
<p>For this tutorial, we shall use the most common type of neural network: fully connected feedforward neural network <code class="docutils literal notranslate"><span class="pre">nk.machine.FFNN</span></code>. Other types of neural networks available will be discussed in other tutorials.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[7]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span>import netket.nn as nknn
import jax.numpy as jnp

class FFNN(nknn.Module):
    @nknn.compact
    def __call__(self, x):
        x = nknn.Dense(features=2*x.shape[-1], use_bias=True, dtype=np.complex128, kernel_init=nknn.initializers.normal(stddev=0.01), bias_init=nknn.initializers.normal(stddev=0.01))(x)
        x = nknn.log_cosh(x)
        x = jnp.sum(x, axis=-1)
        return x

model = FFNN()
</pre></div>
</div>
</div>
</div>
<div class="section" id="3)-Variational-Monte-Carlo-Optimisation">
<h2>3) Variational Monte Carlo Optimisation<a class="headerlink" href="#3)-Variational-Monte-Carlo-Optimisation" title="Permalink to this headline"></a></h2>
<p>We have now set up our model (Hamiltonian, Graph, Hilbert Space) and can proceed to optimise the variational ansatz we chose, namely the <code class="docutils literal notranslate"><span class="pre">ffnn</span></code> machine.</p>
<p>To setup the variational Monte Carlo optimisation tool, we have to provide a sampler <code class="docutils literal notranslate"><span class="pre">nk.sampler</span></code> and an optimizer <code class="docutils literal notranslate"><span class="pre">nk.optimizer</span></code>.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[8]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span># We shall use an exchange Sampler which preserves the global magnetization (as this is a conserved quantity in the model)
sa = nk.sampler.MetropolisExchange(hilbert=hi, graph=g, d_max = 2)

# Construct the variational state
vs = nk.variational.MCState(sa, model, n_samples=1000)

# We choose a basic, albeit important, Optimizer: the Stochastic Gradient Descent
opt = nk.optimizer.Sgd(learning_rate=0.01)

# Stochastic Reconfiguration
sr = nk.optimizer.SR(diag_shift=0.01)

# We can then specify a Variational Monte Carlo object, using the Hamiltonian, sampler and optimizers chosen.
# Note that we also specify the method to learn the parameters of the wave-function: here we choose the efficient
# Stochastic reconfiguration (Sr), here in an iterative setup
gs = nk.VMC(hamiltonian=op, optimizer=opt, variational_state=vs, preconditioner=sr)
</pre></div>
</div>
</div>
</div>
<div class="section" id="4)-Measuring-Observables">
<h2>4) Measuring Observables<a class="headerlink" href="#4)-Measuring-Observables" title="Permalink to this headline"></a></h2>
<p>Before running the optimization, it can be helpful to add some observables to keep track off during the optimization. For our purpose, let us measure the antiferromagnetic structure factor, defined as:</p>
<div class="math notranslate nohighlight">
\[\frac{1}{L} \sum_{ij} \langle \hat{\sigma}_{i}^z \cdot \hat{\sigma}_{j}^z\rangle e^{i\pi(i-j)}\]</div>
<p>.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[9]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span># We need to specify the local operators as a matrix acting on a local Hilbert space
sf = []
sites = []
structure_factor = nk.operator.LocalOperator(hi, dtype=complex)
for i in range(0, L):
    for j in range(0, L):
        structure_factor += (nk.operator.spin.sigmaz(hi, i)*nk.operator.spin.sigmaz(hi, j))*((-1)**(i-j))/L

</pre></div>
</div>
</div>
<p>Once again, notice that we had to multiply the exchange operator (matrix) by some factor. This is to account for the Marshall basis rotation we made in our model.</p>
<p>We can now optimize our variational ansatz. The optimization data for each iteration will be stored in a log file, which contains the following information: 1. Mean, variance and uncertainty in the Energy $ <span class="math">\langle `:nbsphinx-math:</span>hat{H}` <span class="math">\rangle `$ 2. Mean, variance and uncertainty in the Energy Variance, $
:nbsphinx-math:</span>langle`:nbsphinx-math:<cite>hat{H}</cite><sup>{2}:nbsphinx-math:</sup>rangle`-<span class="math">\langle `:nbsphinx-math:</span>hat{H}`:nbsphinx-math:<cite>rangle`</cite>{2}$. 3. Acceptance rates of the sampler 4. Mean, variance and uncertainty of observables (if specified)</p>
<p>Now let’s learn the ground-state!</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[10]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span># Run the optimization protocol
gs.run(out=&#39;test&#39;, n_iter=600, obs={&#39;Structure Factor&#39;: structure_factor})
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
100%|██████████| 600/600 [01:38&lt;00:00,  6.11it/s, Energy=-23.0617-0.0024j ± 0.0037 [σ²=0.0139, R̂=0.9974]]
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[10]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
(JsonLog(&#39;test&#39;, mode=write, autoflush_cost=0.005)
   Runtime cost:
        Log:    0.33330416679382324
        Params: 0.003678560256958008,)
</pre></div></div>
</div>
</div>
<div class="section" id="5)-Data-Visualisation">
<h2>5) Data Visualisation<a class="headerlink" href="#5)-Data-Visualisation" title="Permalink to this headline"></a></h2>
<p>Now that we have optimized our machine to find the ground state of the <span class="math notranslate nohighlight">\(J_1-J_2\)</span> model, let’s look at what we have. The relevant data are stored in the “.log” file while the optimized parameters are in the “.wf” file. The files are all in json format.</p>
<p>We shall extract the energy as well as specified observables (antiferromagnetic structure factor in our case) from the “.log” file.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[11]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span># Load the data from the .log file
import json

data=json.load(open(&quot;test.log&quot;))

iters = data[&#39;Energy&#39;][&#39;iters&#39;]
energy=data[&#39;Energy&#39;][&#39;Mean&#39;][&#39;real&#39;]
sf=data[&#39;Structure Factor&#39;][&#39;Mean&#39;][&#39;real&#39;]
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span>
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[12]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span>fig, ax1 = plt.subplots()
ax1.plot(iters, energy, color=&#39;blue&#39;, label=&#39;Energy&#39;)
ax1.set_ylabel(&#39;Energy&#39;)
ax1.set_xlabel(&#39;Iteration&#39;)
ax2 = ax1.twinx()
ax2.plot(iters, np.array(sf), color=&#39;green&#39;, label=&#39;Structure Factor&#39;)
ax2.set_ylabel(&#39;Structure Factor&#39;)
ax1.legend(loc=2)
ax2.legend(loc=1)
plt.show()
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/tutorials_j1j2_24_0.png" src="../_images/tutorials_j1j2_24_0.png" />
</div>
</div>
<p>Let’s also compute the average of those quantities (energy and neel order) over the last 50 iterations where the optimization seems to have converged.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[13]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span>print(r&quot;Structure factor = {0:.3f}({1:.3f})&quot;.format(np.mean(sf[-50:]),
                                              np.std(np.array(sf[-50:]))/np.sqrt(50)))
print(r&quot;Energy = {0:.3f}({1:.3f})&quot;.format(np.mean(energy[-50:]), np.std(energy[-50:])/(np.sqrt(50))))
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Structure factor = 3.827(0.038)
Energy = -23.062(0.001)
</pre></div></div>
</div>
</div>
<div class="section" id="6)-Sanity-Check:-Exact-Diagonalisation">
<h2>6) Sanity Check: Exact Diagonalisation<a class="headerlink" href="#6)-Sanity-Check:-Exact-Diagonalisation" title="Permalink to this headline"></a></h2>
<p>Now that we have obtained some results using VMC, it is a good time to check the quality of our results (at least for small system sizes). For this purpose, Netket provides exact diagonalisation tools.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[14]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span>E_gs, ket_gs = nk.exact.lanczos_ed(op, compute_eigenvectors=True)
structure_factor_gs = (ket_gs.T.conj()@structure_factor.to_linear_operator()@ket_gs).real[0,0]
</pre></div>
</div>
</div>
<p>Here we have specified that we want the corresponding eigenvector (in order to compute observables).</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[15]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span>print(&quot;Exact Ground-state Structure Factor: {0:.3f}&quot;.format(structure_factor_gs))
print(&quot;Exact ground state energy = {0:.3f}&quot;.format(E_gs[0]))
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Exact Ground-state Structure Factor: 3.803
Exact ground state energy = -23.064
</pre></div></div>
</div>
<p>So we see that the both energy and the structure factor we obtained is in agreement with the value obtained via exact diagonalisation.</p>
</div>
</div>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="G-CNN_Honeycomb.html" class="btn btn-neutral float-left" title="Using a group convolutional neural network to learn the ground-state of a symmetric spin model" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="Heisenberg1d.html" class="btn btn-neutral float-right" title="Learning the ground-state of a spin model with different Neural Networks available in NetKet" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2019-2021, The Netket authors - All rights reserved.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>
 

<script type="text/javascript">
    jQuery(function () {
        SphinxRtdTheme.Navigation.enable(true);
      })
</script>

<!-- Temporary footer
<div class="footer-wip">
  <div class="footer-wip-content">
    This documentation refers to an unreleased version of Netket.
  </div>
</div>
-->

<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-118013987-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());
  gtag('config', 'UA-118013987-1');
</script>

<script type="application/ld+json">
{
  "@context": "http://schema.org",
  "@type": "Organization",
  "url": "https://www.netket.org",
  "name": "NetKet",
  "founder": "Giuseppe Carleo",
  "foundingDate": "2018-04-24",
  "foundingLocation" : "New York",
  "logo": "https://www.netket.org/img/logo_small.jpg",
  "sameAs": [
    "https://twitter.com/NetKetOrg",
    "https://github.com/NetKet/netket"
  ],
  "description" : "Netket is an open-source project delivering cutting-edge
  methods for the study of many-body quantum systems with artificial neural
  networks and machine learning techniques."
}
</script>


</body>
</html>